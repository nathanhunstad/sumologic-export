#!/usr/bin/env python
"""
sumologic-export
~~~~~~~~~~~~~~

Export your Sumologic logs easily and quickly.

Usage:
    sumologic-export configure
    sumologic-export
    sumologic-export <start> <stop>
    sumologic-export
        (<start> | -s <start> | --start <start>)
        [(<stop> | -t <stop> | --stop <stop>)]
    sumologic-export (-h | --help)
    sumologic-export (-v | --version)

Written by Randall Degges (http://www.rdegges.com)
"""


from datetime import datetime, timedelta
from json import dumps, loads
from os import chmod, mkdir, SEEK_END, SEEK_SET
from os.path import exists, expanduser
from subprocess import call
from time import sleep
import sys
from docopt import docopt
from requests import get, post, delete


##### GLOBALS
VERSION = '0.0.4'
CONFIG_FILE = expanduser('~/.sumo')


# Pretty print datetime objects.
prettify = lambda x: x.strftime('%Y-%m-%dT%H-%M-%S')


class Exporter(object):
    """Abstraction for exporting Sumologic logs."""

    # Default time increment to move forward by.
    INCREMENT = timedelta(hours=1)

    # Default timerange to use if no dates are specified.
    DEFAULT_TIMERANGE = timedelta(days=30)

    # Sumologic API constants.
    SUMOLOGIC_URL = 'https://api.us2.sumologic.com/api/v1/search/jobs'
    SUMOLOGIC_HEADERS = {
        'content-type': 'application/json',
        'accept': 'application/json',
    }

    # Amount of time to wait for API response.
    TIMEOUT = 20

    # Sumologic timezone to specify.
    TIMEZONE = 'PST'

    # Amount of time to pause before requesting Sumologic logs.  60 seconds
    # seems to be a good amount of time.
    SLEEP_SECONDS = 60

    # The amount of logs to download from Sumologic per page.  The higher this
    # is, the more memory is used, but the faster the exports are.
    MESSAGES_PER_PAGE = 10000

    def __init__(self):
        """
        Initialize this exporter.

        This includes:

        - Loading credentials.
        - Prepping the environment.
        - Setting up class variables.
        """
        if not exists(CONFIG_FILE):
            print 'No credentials found! Run sumologic-export configure'
            raise SystemExit()

        if not exists('exports'):
            mkdir('exports')

        with open(CONFIG_FILE, 'rb') as cfg:
            creds = loads(cfg.read())
            self.credentials = (creds['accessid'], creds['accesskey'])

        self.cookies = None

    def init_dates(self, start, stop):
        """
        Validate and initialize the date inputs we get from the user.

        We'll:

        - Ensure the dates are valid.
        - Perform cleanup.
        - If no dates are specified, we'll set defaults.
        """
        if start:
            try:
                self.start = datetime.strptime(start, '%Y-%m-%d').replace(hour=0, minute=0, second=0, microsecond=0)
            except:
                print 'Invalid date format. Format must be YYYY-MM-DD.'
                raise SystemExit(1)

            if self.start > datetime.now():
                print 'Start date must be in the past!'
                raise SystemExit(1)
        else:
            self.start = (datetime.now() - self.DEFAULT_TIMERANGE).replace(hour=0, minute=0, second=0, microsecond=0)

        if stop:
            try:
                self.stop = datetime.strptime(stop, '%Y-%m-%d').replace(hour=0, minute=0, second=0, microsecond=0)
            except:
                print 'Invalid date format. Format must be YYYY-MM-DD.'
                raise SystemExit(1)

            if self.stop > datetime.now():
                print 'Stop date must be in the past!'
                raise SystemExit(1)
        else:
            self.stop = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

    def export(self, start, stop):
        """
        Export all Sumologic logs from start to stop.

        All logs will be downloaded one day at a time, and put into a local
        folder named 'exports'.

        :param str start: The datetime at which to start downloading logs.
        :param str stop: The datetime at which to stop downloading logs.
        """
        # Validate / cleanup the date inputs.
        self.init_dates(start, stop)

        print 'Exporting all logs from: %s to %s... This may take a while.\n' % (
            prettify(self.start),
            prettify(self.stop),
        )

        print 'Exporting Logs'
        print '--------------'

        date = self.start
        print 'Start date/time: %s' % prettify(date)
        while date < self.stop:

            # Schedule the Sumologic job.
            job_url = self.create_job(date, date + self.INCREMENT)
            print '-', prettify(date)

            # Pause to allow Sumologic to process this job.
            sleep(self.SLEEP_SECONDS)

            # Figure out how many logs there are for the given date.
            try:
                total_logs = self.get_count(job_url)
            except Exception as e:
                print str(e)
                sys.exit(1)

            # If there are logs to be downloaded, let's do it.
            if total_logs:
                print ' - Downloading %d logs.' % total_logs
                print ' - Writing log file: exports/%s.json' % prettify(date)
                with open('exports/%s.json' % prettify(date), 'wb') as exports:
                    exports.write('[\n')

                    try:
                        for log in self.get_logs(job_url, total_logs):
                            exports.write(dumps(log)+ '\n')
                            exports.write(',\n')
                    except Exception as e:
                        print e
                    # Delete that last comma
                    exports.seek(0, SEEK_END)
                    pos = exports.tell() - 2
                    exports.seek(pos, SEEK_SET)
                    exports.truncate()
                    exports.write(']')
                print ' - Compressing log file: exports/%s.json' % prettify(date)
                call(['gzip', '-9', 'exports/%s.json' % prettify(date)])
            else:
                print ' - No logs found.'
            # Delete job
            try:
                self.delete_job(job_url)
            except Exception as e:
                print str(e)
            # Move forward.
            date += self.INCREMENT

        print '\nFinished downloading logs!'

    def create_job(self, start, stop):
        """
        Request all Sumologic logs for the specified date range.

        :param datetime start: The date to start.
        :param datetime stop: The date to stop.

        :rtype: string
        :returns: The URL of the job.
        """
        while True:
            try:
                resp = post(
                    self.SUMOLOGIC_URL,
                    auth = self.credentials,
                    headers = self.SUMOLOGIC_HEADERS,
                    timeout = self.TIMEOUT,
                    data = dumps({
                        'query': '*',
                        'from': start.isoformat(),
                        'to': stop.isoformat(),
                        'timeZone': self.TIMEZONE,
                    }),
                    cookies = self.cookies,
                )
                print resp.text
                if resp.cookies:
                    self.cookies = resp.cookies

                if resp.status_code == 202:
                    return '%s/%s' % (self.SUMOLOGIC_URL, resp.json()['id'])
                raise Exception('Could not create search job, response status code: {}, response text: {}'.format(resp.status_code,str(resp.text)))
            except:
                sleep(1)

    def get_count(self, job_url):
        """
        Given a Sumologic job URL, figure out how many logs exist.

        :param str job_url: The job URL.

        :rtype: int
        :returns: The amount of logs found in the specified job results.
        """
        while True:
            try:
                resp = get(
                    job_url,
                    auth = self.credentials,
                    headers = self.SUMOLOGIC_HEADERS,
                    timeout = self.TIMEOUT,
                    cookies = self.cookies,
                )
                if resp.cookies:
                    self.cookies = resp.cookies
                print(resp.text)
                if resp.status_code == 200:
                    json = resp.json()
                    if json['state'] == 'DONE GATHERING RESULTS':
                        return json['messageCount']
                    elif json['state'] == 'FORCE PAUSED':
                        raise Exception('State is FORCE PAUSED, exiting...')
                raise Exception('Count of logs encountered an error, response code {}, response text: {}'.format(resp.status_code,str(resp.text)))
            except:
                print('Not done yet, sleeping...')
                sleep(10)

    def get_logs(self, job_url, count):
        """
        Iterate through all Sumologic logs for the given job.

        :param str job_url: The job URL.
        :param int count: The number of logs to retrieve.

        :rtype: generator
        :returns: A generator which returns a single JSON log until all logs have
            been retrieved.
        """
        for page in xrange(0, (count / self.MESSAGES_PER_PAGE) + 1):
            while True:
                try:
                    resp = get(
                        job_url + '/messages',
                        auth = self.credentials,
                        headers = self.SUMOLOGIC_HEADERS,
                        timeout = self.TIMEOUT,
                        params = {
                            'limit': self.MESSAGES_PER_PAGE,
                            'offset': self.MESSAGES_PER_PAGE * page,
                        },
                        cookies = self.cookies,
                    )
                    if resp.cookies:
                        self.cookies = resp.cookies

                    if resp.status_code == 200:
                        json = resp.json()
                        for log in json['messages']:
                            yield log['map']

                        break
                    raise Exception('Get logs returned error, response code {}, response text: {}'.format(resp.status_code,str(resp.text)))
                except Exception as e:
                    print e
                    sleep(1)

    def delete_job(self, job_url):
        """
        Delete SumoLogic search job

        :param string job_url: The job URL

        """
        try:
            resp = delete(
                job_url,
                auth = self.credentials,
                headers = self.SUMOLOGIC_HEADERS,
                timeout = self.TIMEOUT,
                cookies = self.cookies,
            )
            print resp.text
            if resp.cookies:
                self.cookies = resp.cookies

            if resp.status_code >= 200 and resp.status_code < 300:
                return
            raise Exception('Could not delete job, response code {}, response text: {}'.format(resp.status_code,str(resp.text)))
        except:
            raise

def configure():
    """
    Read in and store the user's Sumologic credentials.

    Credentials will be stored in ~/.sumo
    """
    print 'Initializing `sumologic-export`...\n'
    print "To get started, we'll need to get your Sumologic credentials."

    while True:
        accessid = raw_input('Enter Access ID: ').strip()
        accesskey = raw_input('Enter Access Key: ').strip()
        if not (accessid or accesskey):
            print '\nYour Sumologic credentials are needed to continue!\n'
            continue

        print 'Your API credentials are stored in the file:', CONFIG_FILE, '\n'
        print 'Run sumologic-export for usage information.'

        with open(CONFIG_FILE, 'wb') as cfg:
            cfg.write(dumps({
                'accessid': accessid,
                'accesskey': accesskey,
            }, indent=2, sort_keys=True))

        # Make the configuration file only accessible to the current user --
        # this makes the credentials a bit more safe.
        chmod(CONFIG_FILE, 0600)

        break


def main(args):
    """
    Handle command line options.

    :param args: Command line arguments.
    """
    if args['-v']:
        print VERSION
        raise SystemExit()

    elif args['configure']:
        configure()
        raise SystemExit()

    exporter = Exporter()
    exporter.export(args['<start>'], args['<stop>'])


if __name__ == '__main__':
    main(docopt(__doc__, version=VERSION))

